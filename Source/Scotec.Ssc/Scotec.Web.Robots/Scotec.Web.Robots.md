# scotec Software Solutions AB

Die robots.txt ist eine Datei, welche sich im Stammverzeichnis einer Website befindet und Anweisungen für Suchmaschinen enthält. Die Datei wird von den Webcrawlern vor dem Scannen Ihrer Webseiten eingelesen.

In den Anweisungen wird festgelegt, welche Bereiche der Webseite eingelesen werden dürfen. Je nach Struktur lassen sich so ganze Verzeichnisse, ein oder mehrere Unterverzeichnisse oder auch einzelne Dateien vom Crawling ausschließen. Selbst ganze Domains können ausgeschlossen werden, falls eine Indexierung durch die Suchmaschinen nicht erwünscht ist.

Jede Website sollte eine robots.txt-Datei haben. Wenn ein Webcrawlern eine solche Datei nicht findet, besteht die Gefahr, dass nur Teile der Website gecrawlt werden. Da der Inhalt der verschiedenen Seiten Ihrer Website dazu beitragen kann, eine höhere Position in den Suchmaschinenergebnissen zu erreichen, ist es wichtig, dass alle Seiten gecrawlt und indiziert werden.

Weitere Informationen zum Erstellen und zur Anwendung von robots.txt-Dateien finden Sie in der Google Dokumentation im Bereich [Crawling und Indexierung](https://developers.google.com/search/docs/crawling-indexing/robots/intro)



